{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Notes: I ran it on Kaggle using Accelerator GPU"
      ],
      "metadata": {
        "id": "Po_6mMXwxU6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get data from gg Drive"
      ],
      "metadata": {
        "id": "CUpPlkujxjKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update gdown\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "otd9emaoorTA",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:18:26.842142Z",
          "iopub.execute_input": "2022-03-14T09:18:26.842491Z",
          "iopub.status.idle": "2022-03-14T09:18:52.494090Z",
          "shell.execute_reply.started": "2022-03-14T09:18:26.842402Z",
          "shell.execute_reply": "2022-03-14T09:18:52.493214Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data from google drive\n",
        "!gdown --id 1pRcJVhzns_6eZz6iq26w6C9UdGeb4u0B"
      ],
      "metadata": {
        "id": "sfnZmiCCo5zV",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:18:52.496231Z",
          "iopub.execute_input": "2022-03-14T09:18:52.496508Z",
          "iopub.status.idle": "2022-03-14T09:18:56.513309Z",
          "shell.execute_reply.started": "2022-03-14T09:18:52.496474Z",
          "shell.execute_reply": "2022-03-14T09:18:56.512418Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip data\n",
        "!unzip -q ./makeup_data.zip -d ./"
      ],
      "metadata": {
        "id": "GHhFY-peppNU",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:18:56.514868Z",
          "iopub.execute_input": "2022-03-14T09:18:56.515446Z",
          "iopub.status.idle": "2022-03-14T09:18:59.327189Z",
          "shell.execute_reply.started": "2022-03-14T09:18:56.515405Z",
          "shell.execute_reply": "2022-03-14T09:18:59.326246Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Module/Library"
      ],
      "metadata": {
        "id": "Mowcs8CmyKGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "mz6AHPSsoy_n",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:18:59.329943Z",
          "iopub.execute_input": "2022-03-14T09:18:59.330208Z",
          "iopub.status.idle": "2022-03-14T09:19:04.952528Z",
          "shell.execute_reply.started": "2022-03-14T09:18:59.330174Z",
          "shell.execute_reply": "2022-03-14T09:19:04.951706Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "qxpxxhlWor6H",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:04.953997Z",
          "iopub.execute_input": "2022-03-14T09:19:04.954280Z",
          "iopub.status.idle": "2022-03-14T09:19:04.965008Z",
          "shell.execute_reply.started": "2022-03-14T09:19:04.954240Z",
          "shell.execute_reply": "2022-03-14T09:19:04.963742Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n"
      ],
      "metadata": {
        "id": "6wr3MqEsp0C4",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:04.967473Z",
          "iopub.execute_input": "2022-03-14T09:19:04.967995Z",
          "iopub.status.idle": "2022-03-14T09:19:07.047364Z",
          "shell.execute_reply.started": "2022-03-14T09:19:04.967955Z",
          "shell.execute_reply": "2022-03-14T09:19:07.045736Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config Parameters"
      ],
      "metadata": {
        "id": "yzyCltaHyOQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE  = 1\n",
        "IMG_HEIGHT  = 256\n",
        "IMG_WIDTH   = 256\n",
        "IMG_CHANNEL = 3\n",
        "\n",
        "# Path to folder de-makeup data \n",
        "IMG_PATH = \"./makeup_data\"\n",
        "BUFFER_SIZE = 100"
      ],
      "metadata": {
        "id": "POeJWnmcp1e5",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:07.052165Z",
          "iopub.execute_input": "2022-03-14T09:19:07.053565Z",
          "iopub.status.idle": "2022-03-14T09:19:07.058855Z",
          "shell.execute_reply.started": "2022-03-14T09:19:07.053509Z",
          "shell.execute_reply": "2022-03-14T09:19:07.057998Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "Vhjx7fHkyVGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(image_file):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    image_path : string \n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    input_image: tf.Tensor (tf.float32)  image makeup\n",
        "    target_image: tf.Tensor (tf.float32) image demakeup\n",
        "    \"\"\"\n",
        "    # Read image\n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.image.decode_jpeg(image)\n",
        "\n",
        "    #Resize image \n",
        "    image  = tf.image.resize(image, (IMG_HEIGHT, IMG_WIDTH*3))\n",
        "\n",
        "    # Split image \n",
        "    target_image = image[:, IMG_WIDTH : IMG_WIDTH*2, :]\n",
        "    input_image = image[:, IMG_WIDTH*2: :]\n",
        "    \n",
        "    # Convert to float32\n",
        "    input_image  = tf.cast(input_image, tf.float32)\n",
        "    target_image = tf.cast(target_image, tf.float32)\n",
        "\n",
        "    return input_image, target_image"
      ],
      "metadata": {
        "id": "9vKpsuXjf8-D",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:07.060644Z",
          "iopub.execute_input": "2022-03-14T09:19:07.060953Z",
          "iopub.status.idle": "2022-03-14T09:19:07.070196Z",
          "shell.execute_reply.started": "2022-03-14T09:19:07.060914Z",
          "shell.execute_reply": "2022-03-14T09:19:07.069195Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./makeup_data/train/0.png\"\n",
        "input_image, target_image = load(path)\n",
        "\n",
        "print(input_image.shape)\n",
        "print(target_image.shape)\n",
        "\n",
        "\n",
        "# casting to int for matplotlib to show the image\n",
        "plt.figure()\n",
        "plt.imshow(input_image/255.0)\n",
        "plt.figure()\n",
        "plt.imshow(target_image/255.0)"
      ],
      "metadata": {
        "id": "xIaT4dT680dL",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:07.071467Z",
          "iopub.execute_input": "2022-03-14T09:19:07.071658Z",
          "iopub.status.idle": "2022-03-14T09:19:07.598021Z",
          "shell.execute_reply.started": "2022-03-14T09:19:07.071634Z",
          "shell.execute_reply": "2022-03-14T09:19:07.597247Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function()\n",
        "def random_flip(input_image, target_image):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_image: tf.Tensor (tf.float32)  image makeup\n",
        "    target_image: tf.Tensor (tf.float32) image demakeup\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    input_image: tf.Tensor (tf.float32)  image makeup - flip (50%)\n",
        "    target_image: tf.Tensor (tf.float32) image demakeup - flip (50%)\n",
        "    \"\"\"\n",
        "\n",
        "    # random 50% flip right or left\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image  = tf.image.flip_left_right(input_image)\n",
        "        target_image = tf.image.flip_left_right(target_image)\n",
        "\n",
        "    return input_image, target_image\n",
        "\n",
        "    \n",
        "def processing_image(input_image, target_image):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_image: tf.Tensor (tf.float32)  image makeup\n",
        "    target_image: tf.Tensor (tf.float32) image demakeup\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    input_image: tf.Tensor (tf.float32) - processing_image\n",
        "    target_image: tf.Tensor (tf.float32)- processing_image\n",
        "    \"\"\"\n",
        "\n",
        "    # Use preprocess input resnet50 because of using Pretrained model\n",
        "    # input_image = keras.applications.resnet50.preprocess_input(input_image)\n",
        "\n",
        "    input_image  = (input_image / 127.5) - 1\n",
        "    target_image = (target_image / 127.5) - 1\n",
        "\n",
        "    return input_image, target_image\n",
        "\n",
        "\n",
        "def load_image_train(image_file):\n",
        "    \"\"\"\n",
        "    ----------\n",
        "    input_image: tf.Tensor (tf.float32)  image makeup\n",
        "    target_image: tf.Tensor (tf.float32) image demakeup\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    input_image: tf.Tensor (tf.float32)  load image makeup for training\n",
        "    target_image: tf.Tensor (tf.float32) load image demakeup for training\n",
        "    \"\"\"\n",
        "    # load image\n",
        "    input_image, target_image = load(image_file)\n",
        "\n",
        "    # random_flip\n",
        "    input_image, target_image = random_flip(input_image, target_image)\n",
        "\n",
        "    # processing_image\n",
        "    input_image, target_image = processing_image(input_image, target_image)\n",
        "    \n",
        "    return input_image, target_image\n",
        "\n",
        "\n",
        "def load_image_val(image_file):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_image: tf.Tensor (tf.float32)  image makeup\n",
        "    target_image: tf.Tensor (tf.float32) image demakeup\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    input_image: tf.Tensor (tf.float32)  load image makeup for validation\n",
        "    target_image: tf.Tensor (tf.float32) load image demakeup for validation\n",
        "    \"\"\"\n",
        "    # dùng hàm load để load ảnh \n",
        "    input_image, target_image = load(image_file)\n",
        "    \n",
        "    # dùng hàm processing_image để xử lý ảnh\n",
        "    input_image, target_image = processing_image(input_image, target_image)\n",
        "    \n",
        "    return input_image, target_image"
      ],
      "metadata": {
        "id": "v14d8sIW7S0h",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:07.600738Z",
          "iopub.execute_input": "2022-03-14T09:19:07.601040Z",
          "iopub.status.idle": "2022-03-14T09:19:07.611664Z",
          "shell.execute_reply.started": "2022-03-14T09:19:07.600996Z",
          "shell.execute_reply": "2022-03-14T09:19:07.610857Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.list_files(str(IMG_PATH + '/train/*.png'))\n",
        "train_dataset = train_dataset.map(load_image_train,\n",
        "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "tErBBKjPk2qn",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:07.613060Z",
          "iopub.execute_input": "2022-03-14T09:19:07.613329Z",
          "iopub.status.idle": "2022-03-14T09:19:07.989601Z",
          "shell.execute_reply.started": "2022-03-14T09:19:07.613293Z",
          "shell.execute_reply": "2022-03-14T09:19:07.988799Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.data.Dataset.list_files(str(IMG_PATH + '/val/*.png'))\n",
        "val_dataset = val_dataset.map(load_image_val)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "BDE158fSlk20",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:07.991162Z",
          "iopub.execute_input": "2022-03-14T09:19:07.991442Z",
          "iopub.status.idle": "2022-03-14T09:19:08.063069Z",
          "shell.execute_reply.started": "2022-03-14T09:19:07.991404Z",
          "shell.execute_reply": "2022-03-14T09:19:08.062367Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = tf.data.Dataset.list_files(str(IMG_PATH + '/test/*.png'))\n",
        "test_dataset = test_dataset.map(load_image_val)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "jcHgg9RGlnrP",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:08.064239Z",
          "iopub.execute_input": "2022-03-14T09:19:08.064526Z",
          "iopub.status.idle": "2022-03-14T09:19:08.091557Z",
          "shell.execute_reply.started": "2022-03-14T09:19:08.064491Z",
          "shell.execute_reply": "2022-03-14T09:19:08.090853Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model "
      ],
      "metadata": {
        "id": "2di5BB-MyaDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BuildRes50Unet():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def conv_block(self, inputs, num_filters):\n",
        "        \"\"\"Two convolution \n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs: tf.Tensor \n",
        "        num_filters: int \n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        x: tf.Tensor \n",
        "            inputs pass 2 convlution block (Conv2D, LayerNormalization, Activation function LeakyReLU)\n",
        "        \"\"\"\n",
        "        # Init weight\n",
        "        initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "        # Conv 1\n",
        "        x = layers.Conv2D(num_filters, 3, strides=1, padding='same',\n",
        "                          kernel_initializer=initializer, use_bias=False)(inputs)\n",
        "        x = layers.LayerNormalization()(x)\n",
        "        x = layers.LeakyReLU()(x)\n",
        "\n",
        "        # Conv 2\n",
        "        x = layers.Conv2D(num_filters, 3, strides=1, padding='same',\n",
        "                          kernel_initializer=initializer, use_bias=False)(x)\n",
        "        x = layers.LayerNormalization()(x)\n",
        "        x = layers.LeakyReLU()(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    \n",
        "    def upsample_concate_block(self, inputs, skip_connection, num_filters):\n",
        "        \"\"\"Upsampling, skip connection and via 2 convolution block\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs: tf.Tensor \n",
        "        skip_connection: tf.Tensor \n",
        "        num_filters: int \n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        x: tf.Tensor \n",
        "        \"\"\"\n",
        "        \n",
        "        # Upsampling \n",
        "        x = layers.UpSampling2D(interpolation='bilinear')(inputs)\n",
        "\n",
        "        # Concatenate tensor upsample and skip connection\n",
        "        x = layers.Concatenate()([x, skip_connection])\n",
        "\n",
        "        # Via 2 convolution block\n",
        "        x = self.conv_block(x, num_filters)\n",
        "\n",
        "        return x    \n",
        "    \n",
        "    def build_model(self, input_shape):\n",
        "        \"\"\"Build Unet architecture use pretrained backbone (encoder)\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_shape: Tuple  \n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        model: tf.keras.Model\n",
        "            Unet model \n",
        "        \"\"\"\n",
        "        # Input layer \n",
        "        inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "        # Encoder\n",
        "\n",
        "        # Get pretrained backbone \n",
        "        \"\"\" Pre-trained ResNet50 Model \"\"\"\n",
        "        resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "\n",
        "        \"\"\" Encoder \"\"\"\n",
        "        s1 = resnet50.layers[0].output         \n",
        "        s2 = resnet50.get_layer(\"conv1_relu\").output        \n",
        "        s3 = resnet50.get_layer(\"conv2_block3_out\").output  \n",
        "        s4 = resnet50.get_layer(\"conv3_block4_out\").output  \n",
        "\n",
        "        \"\"\" Bridge \"\"\"\n",
        "        b1 = resnet50.get_layer(\"conv4_block6_out\").output  \n",
        "\n",
        "        \"\"\" Decoder \"\"\"\n",
        "        d1 = self.upsample_concate_block(b1, s4, 512)             \n",
        "        d2 = self.upsample_concate_block(d1, s3, 256)                  \n",
        "        d3 = self.upsample_concate_block(d2, s2, 128)                   \n",
        "        d4 = self.upsample_concate_block(d3, s1, 64)  \n",
        "        \n",
        "        \"\"\" Output \"\"\"\n",
        "        # Use tanh for output [-1: 1]\n",
        "        outputs = layers.Conv2D(filters=input_shape[-1], kernel_size=(1,1), activation='tanh',\n",
        "                                      kernel_initializer='he_normal', use_bias=False)(d4)\n",
        "        \n",
        "        # Value input and output [-1:1]\n",
        "        model = Model(inputs=[inputs], outputs=[outputs])\n",
        "        \n",
        "        return model"
      ],
      "metadata": {
        "id": "7OqvRnm1mJsm",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BuildRes50Unet()\n",
        "res50Unet = model.build_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL))"
      ],
      "metadata": {
        "id": "2ljQHjdUnZGo",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res50Unet.summary()"
      ],
      "metadata": {
        "id": "1VWY7Ot9nasu",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config and Compile Model"
      ],
      "metadata": {
        "id": "cqcAMAE4yi9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show Generated Images and Evaluation Function"
      ],
      "metadata": {
        "id": "lk08EJHMyrjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, epoch, val_ds):  \n",
        "    psnr_mean = 0.0\n",
        "    count = 0\n",
        "\n",
        "    # Get input and targets from validation dataset\n",
        "    for inputs, targets in val_ds:\n",
        "        fake = model([inputs], training=True)\n",
        "         \n",
        "        # Scale to [0,1] and compute PSNR\n",
        "        psnr = tf.image.psnr(fake*0.5 + 0.5, targets*0.5 + 0.5, max_val=1.0)\n",
        "\n",
        "        __psnr_mean = tf.math.reduce_mean(psnr)\n",
        "        \n",
        "        psnr_mean += __psnr_mean\n",
        "        count =count + 1\n",
        "    \n",
        "    psnr_mean = psnr_mean/count\n",
        "    print('-------- psnr: ', psnr_mean.numpy(), '   ----- epoch: ', epoch, '  count: ', count)\n",
        "    \n",
        "    return psnr_mean\n",
        "    \n",
        "def generate_images(model, inputs, targets, epoch, pnsr):\n",
        "    # Show images genearation from validation dataset\n",
        "    fake = model([inputs], training=True)\n",
        "    plt.figure(figsize=(15,20))\n",
        "    \n",
        "    # Get one images\n",
        "    display_list = [inputs[0], targets[0], fake[0]]\n",
        "    title = ['Input', 'Real', 'Predicted']    \n",
        "\n",
        "    # Save output better performance than \n",
        "    output = np.concatenate([display_list[0], display_list[1], display_list[2]], axis=1)\n",
        "    output = (output * 0.5 + 0.5) * 255\n",
        "    output = output.astype(np.uint8)\n",
        "    Image.fromarray(output).save(f\"./save_result/validation_results/epoch:{epoch} pnsr:{pnsr}.png\")\n",
        "    \n",
        "    # Show output\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "    plt.show()        "
      ],
      "metadata": {
        "id": "LpHS30teo68_",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Folder to save result"
      ],
      "metadata": {
        "id": "AtPXGWQNzEvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"./save_result\", exist_ok=True)\n",
        "os.makedirs(\"./save_result/validation_results\", exist_ok=True)\n",
        "os.makedirs(\"./save_result/testing_results\", exist_ok=True)\n",
        "os.makedirs(\"./save_result/save_model\", exist_ok=True)"
      ],
      "metadata": {
        "id": "9hk1kp3iDiXi",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:23:49.329433Z",
          "iopub.execute_input": "2022-03-14T09:23:49.330038Z",
          "iopub.status.idle": "2022-03-14T09:23:49.335590Z",
          "shell.execute_reply.started": "2022-03-14T09:23:49.330004Z",
          "shell.execute_reply": "2022-03-14T09:23:49.334645Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss"
      ],
      "metadata": {
        "id": "xPIBDAVZyu5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PeceptualLoss():\n",
        "    def __init__(self, input_shape = (256,256,3)):\n",
        "        self.input_shape = input_shape    \n",
        "    \n",
        "    def get_extractor(self):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_shape: tuple \n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        model:  tf.keras.Model \n",
        "            pretrained model (vgg19) to extract feature for perceptual loss\n",
        "        \"\"\"\n",
        "\n",
        "        vgg = VGG19(input_shape= self.input_shape, include_top=False, weights='imagenet')\n",
        "        model = tf.keras.Model(vgg.input, vgg.layers[20].output)\n",
        "        \n",
        "        return model\n",
        "        \n",
        "        \n",
        "    def percep_loss(self, target_image, fake_image):\n",
        "\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        target_image: tf.tensor  \n",
        "        fake_image: tf.tensor  \n",
        "        Returns\n",
        "        -------\n",
        "        loss:  tf.tensor\n",
        "        \"\"\"\n",
        "        \n",
        "        # Get feature\n",
        "        model_vgg = self.get_extractor()\n",
        "        \n",
        "        # Get mean square error\n",
        "        mean_squared_error = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "        # Change chanel = 3 if chanel = 1\n",
        "        if target_image.shape[3]==1:\n",
        "            target_image = tf.concat([target_image, target_image, target_image], 3)\n",
        "\n",
        "        if fake_image.shape[3]==1:\n",
        "            fake_image = tf.concat([fake_image, fake_image, fake_image], 3)\n",
        "\n",
        "        # Get feature for taget and fake image\n",
        "        target_image_feature = model_vgg(target_image)\n",
        "        fake_image_feature = model_vgg(fake_image)\n",
        "        \n",
        "        # Compute mean square error\n",
        "        loss = mean_squared_error(target_image_feature, fake_image_feature)    \n",
        "\n",
        "        return loss        "
      ],
      "metadata": {
        "id": "_E3lQ7XVpMlg",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init perceptual loss\n",
        "per_loss = PeceptualLoss(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL))"
      ],
      "metadata": {
        "id": "G-slj6ZepNbk",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake, target, loss_type='L1'):\n",
        "    loss_list = [\"L1\", \"Percep\"]\n",
        "    assert loss_type in loss_list\n",
        "\n",
        "    # L1 loss\n",
        "    if loss_type == loss_list[0]:\n",
        "        loss = tf.reduce_mean(tf.abs(fake-target))\n",
        "\n",
        "    # Perceptual Loss\n",
        "    elif loss_type == loss_list[1]:\n",
        "        loss = per_loss.percep_loss(target, fake)\n",
        "    \n",
        "    return loss"
      ],
      "metadata": {
        "id": "8u3MjP6-pO8B",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "0yDpAWoSy4s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)"
      ],
      "metadata": {
        "id": "1gT7pEgVy8Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation"
      ],
      "metadata": {
        "id": "y57vhfnWzaJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # output\n",
        "        fake = res50Unet([inputs], training=True)     \n",
        "        loss = generator_loss(fake, targets)\n",
        "        \n",
        "    generator_gradients = tape.gradient(loss, res50Unet.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(generator_gradients, res50Unet.trainable_variables))\n",
        "    \n",
        "    return loss\n",
        "\n",
        "    \n",
        "    \n",
        "def fit(train_ds, epochs, val_ds):\n",
        "    best_pnsr = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        # Train\n",
        "        total_loss = 0.0\n",
        "        for inputs, targets in train_ds:\n",
        "            loss = train_step(inputs, targets)\n",
        "            total_loss = total_loss + loss\n",
        "\n",
        "        total_loss = (total_loss/len(train_ds))*100\n",
        "        print('epoch: {}   loss: {}'.format(epoch, total_loss))\n",
        "        \n",
        "        pnsr = evaluate(res50Unet, epoch, val_ds)        \n",
        "        if best_pnsr < pnsr:\n",
        "            best_pnsr = pnsr\n",
        "            res50Unet.save(\"./save_result/save_model/model-resnet-50-unet.h5\")\n",
        "            for inputs, targets in val_ds.take(1):\n",
        "                generate_images(res50Unet, inputs, targets, epoch, best_pnsr)\n",
        "                print(\"Save result successfully!\")\n"
      ],
      "metadata": {
        "id": "pDDWHSO6qLas",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 150\n",
        "fit(train_dataset, EPOCHS, val_dataset)"
      ],
      "metadata": {
        "id": "tsRUGVbXqLXa",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Results"
      ],
      "metadata": {
        "id": "9mqLYrizzhaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(15):\n",
        "    for inputs, targets in test_dataset.take(1):\n",
        "        fake = res50Unet([inputs], training=True)\n",
        "        plt.figure(figsize=(15,20))\n",
        "\n",
        "        display_list = [inputs[0], targets[0], fake[0]]\n",
        "        title = ['Input Left', 'Real Left', 'Predicted Left']    \n",
        "        \n",
        "        # Save output testing\n",
        "        output = np.concatenate([display_list[0], display_list[1], display_list[2]], axis=1)\n",
        "        output = (output * 0.5 + 0.5) * 255\n",
        "        output = output.astype(np.uint8)\n",
        "        Image.fromarray(output).save(f\"./save_result/testing_results/testing_result_{x}.png\")\n",
        "        \n",
        "        for i in range(3):\n",
        "            plt.subplot(1, 3, i+1)\n",
        "            plt.title(title[i])\n",
        "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "            plt.axis('off')\n",
        "        plt.show() "
      ],
      "metadata": {
        "id": "JIzDORGgqLUY",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Resuls"
      ],
      "metadata": {
        "id": "xfZSgKbPzyK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res50Unet.save(\"./save_result/save_model/model-resnet-50-unet-final\")"
      ],
      "metadata": {
        "id": "7CjG-v4ToW-0",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r save_result.zip save_result"
      ],
      "metadata": {
        "id": "jl6d39IPoW-1",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load model to use"
      ],
      "metadata": {
        "id": "YzUgwK8B0C7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "from tensorflow import keras\n",
        "res50Unet = keras.models.load_model('../input/model-unet-resnet50-l1/model-resnet-50-unet.h5')"
      ],
      "metadata": {
        "id": "yWG65IBcoW-3",
        "execution": {
          "iopub.status.busy": "2022-03-14T09:19:54.906687Z",
          "iopub.execute_input": "2022-03-14T09:19:54.906949Z",
          "iopub.status.idle": "2022-03-14T09:19:57.831207Z",
          "shell.execute_reply.started": "2022-03-14T09:19:54.906922Z",
          "shell.execute_reply": "2022-03-14T09:19:57.830378Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(15):\n",
        "    for inputs, targets in test_dataset.take(1):\n",
        "        fake = res50Unet([inputs], training=True)\n",
        "        plt.figure(figsize=(15,20))\n",
        "\n",
        "        display_list = [inputs[0], targets[0], fake[0]]\n",
        "        title = ['Input Left', 'Real Left', 'Predicted Left']    \n",
        "        \n",
        "        for i in range(3):\n",
        "            plt.subplot(1, 3, i+1)\n",
        "            plt.title(title[i])\n",
        "            plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "            plt.axis('off')\n",
        "        plt.show() "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-03-14T09:27:31.924210Z",
          "iopub.execute_input": "2022-03-14T09:27:31.924882Z",
          "iopub.status.idle": "2022-03-14T09:27:41.574438Z",
          "shell.execute_reply.started": "2022-03-14T09:27:31.924843Z",
          "shell.execute_reply": "2022-03-14T09:27:41.573696Z"
        },
        "trusted": true,
        "id": "7j-tJtoVxUCm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}